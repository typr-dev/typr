/**
 * File has been automatically generated by `typo`.
 *
 * IF YOU CHANGE THIS FILE YOUR CHANGES WILL BE OVERWRITTEN.
 */
package adventureworks.public.flaff

import adventureworks.public.ShortText
import cats.instances.list.catsStdInstancesForList
import doobie.free.connection.ConnectionIO
import doobie.postgres.syntax.FragmentOps
import doobie.syntax.SqlInterpolator.SingleFragment.fromWrite
import doobie.util.Write
import doobie.util.meta.Meta
import doobie.util.update.Update
import fs2.Stream
import typr.dsl.DeleteBuilder
import typr.dsl.SelectBuilder
import typr.dsl.UpdateBuilder
import doobie.syntax.string.toSqlInterpolator

class FlaffRepoImpl extends FlaffRepo {
  override def delete: DeleteBuilder[FlaffFields, FlaffRow] = DeleteBuilder.of(""""public"."flaff"""", FlaffFields.structure, FlaffRow.read)

  override def deleteById(compositeId: FlaffId): ConnectionIO[Boolean] = sql"""delete from "public"."flaff" where "code" = ${fromWrite(compositeId.code)(new Write.Single(ShortText.put))} AND "another_code" = ${fromWrite(compositeId.anotherCode)(new Write.Single(Meta.StringMeta.put))} AND "some_number" = ${fromWrite(compositeId.someNumber)(new Write.Single(Meta.IntMeta.put))} AND "specifier" = ${fromWrite(compositeId.specifier)(new Write.Single(ShortText.put))}""".update.run.map(_ > 0)

  override def deleteByIds(compositeIds: Array[FlaffId]): ConnectionIO[Int] = {
    val code = compositeIds.map(_.code)
    val anotherCode = compositeIds.map(_.anotherCode)
    val someNumber = compositeIds.map(_.someNumber)
    val specifier = compositeIds.map(_.specifier)
    sql"""delete
    from "public"."flaff"
    where ("code", "another_code", "some_number", "specifier")
    in (select unnest(${fromWrite(code)(new Write.Single(ShortText.arrayPut))}), unnest(${fromWrite(anotherCode)(new Write.Single(adventureworks.StringArrayMeta.put))}), unnest(${fromWrite(someNumber)(new Write.Single(adventureworks.IntegerArrayMeta.put))}), unnest(${fromWrite(specifier)(new Write.Single(ShortText.arrayPut))}))
    """.update.run
  }

  override def insert(unsaved: FlaffRow): ConnectionIO[FlaffRow] = {
    sql"""insert into "public"."flaff"("code", "another_code", "some_number", "specifier", "parentspecifier")
    values (${fromWrite(unsaved.code)(new Write.Single(ShortText.put))}::text, ${fromWrite(unsaved.anotherCode)(new Write.Single(Meta.StringMeta.put))}, ${fromWrite(unsaved.someNumber)(new Write.Single(Meta.IntMeta.put))}::int4, ${fromWrite(unsaved.specifier)(new Write.Single(ShortText.put))}::text, ${fromWrite(unsaved.parentspecifier)(new Write.SingleOpt(ShortText.put))}::text)
    returning "code", "another_code", "some_number", "specifier", "parentspecifier"
    """.query(FlaffRow.read).unique
  }

  override def insertStreaming(
    unsaved: Stream[ConnectionIO, FlaffRow],
    batchSize: Int = 10000
  ): ConnectionIO[Long] = new FragmentOps(sql"""COPY "public"."flaff"("code", "another_code", "some_number", "specifier", "parentspecifier") FROM STDIN""").copyIn(unsaved, batchSize)(FlaffRow.pgText)

  override def select: SelectBuilder[FlaffFields, FlaffRow] = SelectBuilder.of(""""public"."flaff"""", FlaffFields.structure, FlaffRow.read)

  override def selectAll: Stream[ConnectionIO, FlaffRow] = sql"""select "code", "another_code", "some_number", "specifier", "parentspecifier" from "public"."flaff"""".query(FlaffRow.read).stream

  override def selectById(compositeId: FlaffId): ConnectionIO[Option[FlaffRow]] = sql"""select "code", "another_code", "some_number", "specifier", "parentspecifier" from "public"."flaff" where "code" = ${fromWrite(compositeId.code)(new Write.Single(ShortText.put))} AND "another_code" = ${fromWrite(compositeId.anotherCode)(new Write.Single(Meta.StringMeta.put))} AND "some_number" = ${fromWrite(compositeId.someNumber)(new Write.Single(Meta.IntMeta.put))} AND "specifier" = ${fromWrite(compositeId.specifier)(new Write.Single(ShortText.put))}""".query(FlaffRow.read).option

  override def selectByIds(compositeIds: Array[FlaffId]): Stream[ConnectionIO, FlaffRow] = {
    val code = compositeIds.map(_.code)
    val anotherCode = compositeIds.map(_.anotherCode)
    val someNumber = compositeIds.map(_.someNumber)
    val specifier = compositeIds.map(_.specifier)
    sql"""select "code", "another_code", "some_number", "specifier", "parentspecifier"
    from "public"."flaff"
    where ("code", "another_code", "some_number", "specifier")
    in (select unnest(${fromWrite(code)(new Write.Single(ShortText.arrayPut))}), unnest(${fromWrite(anotherCode)(new Write.Single(adventureworks.StringArrayMeta.put))}), unnest(${fromWrite(someNumber)(new Write.Single(adventureworks.IntegerArrayMeta.put))}), unnest(${fromWrite(specifier)(new Write.Single(ShortText.arrayPut))}))
    """.query(FlaffRow.read).stream
  }

  override def selectByIdsTracked(compositeIds: Array[FlaffId]): ConnectionIO[Map[FlaffId, FlaffRow]] = {
    selectByIds(compositeIds).compile.toList.map { rows =>
      val byId = rows.view.map(x => (x.compositeId, x)).toMap
      compositeIds.view.flatMap(id => byId.get(id).map(x => (id, x))).toMap
    }
  }

  override def update: UpdateBuilder[FlaffFields, FlaffRow] = UpdateBuilder.of(""""public"."flaff"""", FlaffFields.structure, FlaffRow.read)

  override def update(row: FlaffRow): ConnectionIO[Option[FlaffRow]] = {
    val compositeId = row.compositeId
    sql"""update "public"."flaff"
    set "parentspecifier" = ${fromWrite(row.parentspecifier)(new Write.SingleOpt(ShortText.put))}::text
    where "code" = ${fromWrite(compositeId.code)(new Write.Single(ShortText.put))} AND "another_code" = ${fromWrite(compositeId.anotherCode)(new Write.Single(Meta.StringMeta.put))} AND "some_number" = ${fromWrite(compositeId.someNumber)(new Write.Single(Meta.IntMeta.put))} AND "specifier" = ${fromWrite(compositeId.specifier)(new Write.Single(ShortText.put))}
    returning "code", "another_code", "some_number", "specifier", "parentspecifier"""".query(FlaffRow.read).option
  }

  override def upsert(unsaved: FlaffRow): ConnectionIO[FlaffRow] = {
    sql"""insert into "public"."flaff"("code", "another_code", "some_number", "specifier", "parentspecifier")
    values (
      ${fromWrite(unsaved.code)(new Write.Single(ShortText.put))}::text,
    ${fromWrite(unsaved.anotherCode)(new Write.Single(Meta.StringMeta.put))},
    ${fromWrite(unsaved.someNumber)(new Write.Single(Meta.IntMeta.put))}::int4,
    ${fromWrite(unsaved.specifier)(new Write.Single(ShortText.put))}::text,
    ${fromWrite(unsaved.parentspecifier)(new Write.SingleOpt(ShortText.put))}::text
    )
    on conflict ("code", "another_code", "some_number", "specifier")
    do update set
      "parentspecifier" = EXCLUDED."parentspecifier"
    returning "code", "another_code", "some_number", "specifier", "parentspecifier"
    """.query(FlaffRow.read).unique
  }

  override def upsertBatch(unsaved: List[FlaffRow]): Stream[ConnectionIO, FlaffRow] = {
    Update[FlaffRow](
      s"""insert into "public"."flaff"("code", "another_code", "some_number", "specifier", "parentspecifier")
      values (?::text,?,?::int4,?::text,?::text)
      on conflict ("code", "another_code", "some_number", "specifier")
      do update set
        "parentspecifier" = EXCLUDED."parentspecifier"
      returning "code", "another_code", "some_number", "specifier", "parentspecifier""""
    )(FlaffRow.write)
    .updateManyWithGeneratedKeys[FlaffRow]("code", "another_code", "some_number", "specifier", "parentspecifier")(unsaved)(catsStdInstancesForList, FlaffRow.read)
  }

  /** NOTE: this functionality is not safe if you use auto-commit mode! it runs 3 SQL statements */
  override def upsertStreaming(
    unsaved: Stream[ConnectionIO, FlaffRow],
    batchSize: Int = 10000
  ): ConnectionIO[Int] = {
    for {
      _ <- sql"""create temporary table flaff_TEMP (like "public"."flaff") on commit drop""".update.run
      _ <- new FragmentOps(sql"""copy flaff_TEMP("code", "another_code", "some_number", "specifier", "parentspecifier") from stdin""").copyIn(unsaved, batchSize)(FlaffRow.pgText)
      res <- sql"""insert into "public"."flaff"("code", "another_code", "some_number", "specifier", "parentspecifier")
             select * from flaff_TEMP
             on conflict ("code", "another_code", "some_number", "specifier")
             do update set
               "parentspecifier" = EXCLUDED."parentspecifier"
             ;
             drop table flaff_TEMP;""".update.run
    } yield res
  }
}