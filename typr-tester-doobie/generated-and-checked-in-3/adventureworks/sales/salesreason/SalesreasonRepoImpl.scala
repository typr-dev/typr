/**
 * File has been automatically generated by `typo`.
 *
 * IF YOU CHANGE THIS FILE YOUR CHANGES WILL BE OVERWRITTEN.
 */
package adventureworks.sales.salesreason

import adventureworks.customtypes.Defaulted
import adventureworks.customtypes.TypoLocalDateTime
import adventureworks.public.Name
import cats.instances.list.catsStdInstancesForList
import doobie.free.connection.ConnectionIO
import doobie.postgres.syntax.FragmentOps
import doobie.syntax.SqlInterpolator.SingleFragment.fromWrite
import doobie.util.Write
import doobie.util.fragment.Fragment
import doobie.util.update.Update
import fs2.Stream
import typr.dsl.DeleteBuilder
import typr.dsl.SelectBuilder
import typr.dsl.UpdateBuilder
import doobie.syntax.string.toSqlInterpolator

class SalesreasonRepoImpl extends SalesreasonRepo {
  override def delete: DeleteBuilder[SalesreasonFields, SalesreasonRow] = DeleteBuilder.of(""""sales"."salesreason"""", SalesreasonFields.structure, SalesreasonRow.read)

  override def deleteById(salesreasonid: SalesreasonId): ConnectionIO[Boolean] = sql"""delete from "sales"."salesreason" where "salesreasonid" = ${fromWrite(salesreasonid)(using new Write.Single(SalesreasonId.put))}""".update.run.map(_ > 0)

  override def deleteByIds(salesreasonids: Array[SalesreasonId]): ConnectionIO[Int] = sql"""delete from "sales"."salesreason" where "salesreasonid" = ANY(${fromWrite(salesreasonids)(using new Write.Single(SalesreasonId.arrayPut))})""".update.run

  override def insert(unsaved: SalesreasonRow): ConnectionIO[SalesreasonRow] = {
    sql"""insert into "sales"."salesreason"("salesreasonid", "name", "reasontype", "modifieddate")
    values (${fromWrite(unsaved.salesreasonid)(using new Write.Single(SalesreasonId.put))}::int4, ${fromWrite(unsaved.name)(using new Write.Single(Name.put))}::varchar, ${fromWrite(unsaved.reasontype)(using new Write.Single(Name.put))}::varchar, ${fromWrite(unsaved.modifieddate)(using new Write.Single(TypoLocalDateTime.put))}::timestamp)
    returning "salesreasonid", "name", "reasontype", "modifieddate"::text
    """.query(using SalesreasonRow.read).unique
  }

  override def insert(unsaved: SalesreasonRowUnsaved): ConnectionIO[SalesreasonRow] = {
    val fs = List(
      Some((Fragment.const0(s""""name""""), fr"${fromWrite(unsaved.name)(using new Write.Single(Name.put))}::varchar")),
      Some((Fragment.const0(s""""reasontype""""), fr"${fromWrite(unsaved.reasontype)(using new Write.Single(Name.put))}::varchar")),
      unsaved.salesreasonid match {
        case Defaulted.UseDefault() => None
        case Defaulted.Provided(value) => Some((Fragment.const0(s""""salesreasonid""""), fr"${fromWrite(value: SalesreasonId)(using new Write.Single(SalesreasonId.put))}::int4"))
      },
      unsaved.modifieddate match {
        case Defaulted.UseDefault() => None
        case Defaulted.Provided(value) => Some((Fragment.const0(s""""modifieddate""""), fr"${fromWrite(value: TypoLocalDateTime)(using new Write.Single(TypoLocalDateTime.put))}::timestamp"))
      }
    ).flatten
    val q = if (fs.isEmpty) {
      sql"""insert into "sales"."salesreason" default values
      returning "salesreasonid", "name", "reasontype", "modifieddate"::text
      """
    } else {
      val CommaSeparate = Fragment.FragmentMonoid.intercalate(fr", ")
      sql"""insert into "sales"."salesreason"(${CommaSeparate.combineAllOption(fs.map { case (n, _) => n }).get})
      values (${CommaSeparate.combineAllOption(fs.map { case (_, f) => f }).get})
      returning "salesreasonid", "name", "reasontype", "modifieddate"::text
      """
    }
    q.query(using SalesreasonRow.read).unique
  }

  override def insertStreaming(
    unsaved: Stream[ConnectionIO, SalesreasonRow],
    batchSize: Int = 10000
  ): ConnectionIO[Long] = new FragmentOps(sql"""COPY "sales"."salesreason"("salesreasonid", "name", "reasontype", "modifieddate") FROM STDIN""").copyIn(unsaved, batchSize)(using SalesreasonRow.pgText)

  /** NOTE: this functionality requires PostgreSQL 16 or later! */
  override def insertUnsavedStreaming(
    unsaved: Stream[ConnectionIO, SalesreasonRowUnsaved],
    batchSize: Int = 10000
  ): ConnectionIO[Long] = new FragmentOps(sql"""COPY "sales"."salesreason"("name", "reasontype", "salesreasonid", "modifieddate") FROM STDIN (DEFAULT '__DEFAULT_VALUE__')""").copyIn(unsaved, batchSize)(using SalesreasonRowUnsaved.pgText)

  override def select: SelectBuilder[SalesreasonFields, SalesreasonRow] = SelectBuilder.of(""""sales"."salesreason"""", SalesreasonFields.structure, SalesreasonRow.read)

  override def selectAll: Stream[ConnectionIO, SalesreasonRow] = sql"""select "salesreasonid", "name", "reasontype", "modifieddate"::text from "sales"."salesreason"""".query(using SalesreasonRow.read).stream

  override def selectById(salesreasonid: SalesreasonId): ConnectionIO[Option[SalesreasonRow]] = sql"""select "salesreasonid", "name", "reasontype", "modifieddate"::text from "sales"."salesreason" where "salesreasonid" = ${fromWrite(salesreasonid)(using new Write.Single(SalesreasonId.put))}""".query(using SalesreasonRow.read).option

  override def selectByIds(salesreasonids: Array[SalesreasonId]): Stream[ConnectionIO, SalesreasonRow] = sql"""select "salesreasonid", "name", "reasontype", "modifieddate"::text from "sales"."salesreason" where "salesreasonid" = ANY(${fromWrite(salesreasonids)(using new Write.Single(SalesreasonId.arrayPut))})""".query(using SalesreasonRow.read).stream

  override def selectByIdsTracked(salesreasonids: Array[SalesreasonId]): ConnectionIO[Map[SalesreasonId, SalesreasonRow]] = {
    selectByIds(salesreasonids).compile.toList.map { rows =>
      val byId = rows.view.map(x => (x.salesreasonid, x)).toMap
      salesreasonids.view.flatMap(id => byId.get(id).map(x => (id, x))).toMap
    }
  }

  override def update: UpdateBuilder[SalesreasonFields, SalesreasonRow] = UpdateBuilder.of(""""sales"."salesreason"""", SalesreasonFields.structure, SalesreasonRow.read)

  override def update(row: SalesreasonRow): ConnectionIO[Option[SalesreasonRow]] = {
    val salesreasonid = row.salesreasonid
    sql"""update "sales"."salesreason"
    set "name" = ${fromWrite(row.name)(using new Write.Single(Name.put))}::varchar,
    "reasontype" = ${fromWrite(row.reasontype)(using new Write.Single(Name.put))}::varchar,
    "modifieddate" = ${fromWrite(row.modifieddate)(using new Write.Single(TypoLocalDateTime.put))}::timestamp
    where "salesreasonid" = ${fromWrite(salesreasonid)(using new Write.Single(SalesreasonId.put))}
    returning "salesreasonid", "name", "reasontype", "modifieddate"::text""".query(using SalesreasonRow.read).option
  }

  override def upsert(unsaved: SalesreasonRow): ConnectionIO[SalesreasonRow] = {
    sql"""insert into "sales"."salesreason"("salesreasonid", "name", "reasontype", "modifieddate")
    values (
      ${fromWrite(unsaved.salesreasonid)(using new Write.Single(SalesreasonId.put))}::int4,
    ${fromWrite(unsaved.name)(using new Write.Single(Name.put))}::varchar,
    ${fromWrite(unsaved.reasontype)(using new Write.Single(Name.put))}::varchar,
    ${fromWrite(unsaved.modifieddate)(using new Write.Single(TypoLocalDateTime.put))}::timestamp
    )
    on conflict ("salesreasonid")
    do update set
      "name" = EXCLUDED."name",
    "reasontype" = EXCLUDED."reasontype",
    "modifieddate" = EXCLUDED."modifieddate"
    returning "salesreasonid", "name", "reasontype", "modifieddate"::text
    """.query(using SalesreasonRow.read).unique
  }

  override def upsertBatch(unsaved: List[SalesreasonRow]): Stream[ConnectionIO, SalesreasonRow] = {
    Update[SalesreasonRow](
      s"""insert into "sales"."salesreason"("salesreasonid", "name", "reasontype", "modifieddate")
      values (?::int4,?::varchar,?::varchar,?::timestamp)
      on conflict ("salesreasonid")
      do update set
        "name" = EXCLUDED."name",
      "reasontype" = EXCLUDED."reasontype",
      "modifieddate" = EXCLUDED."modifieddate"
      returning "salesreasonid", "name", "reasontype", "modifieddate"::text"""
    )(using SalesreasonRow.write)
    .updateManyWithGeneratedKeys[SalesreasonRow]("salesreasonid", "name", "reasontype", "modifieddate")(unsaved)(using catsStdInstancesForList, SalesreasonRow.read)
  }

  /** NOTE: this functionality is not safe if you use auto-commit mode! it runs 3 SQL statements */
  override def upsertStreaming(
    unsaved: Stream[ConnectionIO, SalesreasonRow],
    batchSize: Int = 10000
  ): ConnectionIO[Int] = {
    for {
      _ <- sql"""create temporary table salesreason_TEMP (like "sales"."salesreason") on commit drop""".update.run
      _ <- new FragmentOps(sql"""copy salesreason_TEMP("salesreasonid", "name", "reasontype", "modifieddate") from stdin""").copyIn(unsaved, batchSize)(using SalesreasonRow.pgText)
      res <- sql"""insert into "sales"."salesreason"("salesreasonid", "name", "reasontype", "modifieddate")
             select * from salesreason_TEMP
             on conflict ("salesreasonid")
             do update set
               "name" = EXCLUDED."name",
             "reasontype" = EXCLUDED."reasontype",
             "modifieddate" = EXCLUDED."modifieddate"
             ;
             drop table salesreason_TEMP;""".update.run
    } yield res
  }
}