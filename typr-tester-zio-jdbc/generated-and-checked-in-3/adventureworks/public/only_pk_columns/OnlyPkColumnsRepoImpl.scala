/**
 * File has been automatically generated by `typo`.
 *
 * IF YOU CHANGE THIS FILE YOUR CHANGES WILL BE OVERWRITTEN.
 */
package adventureworks.public.only_pk_columns

import adventureworks.streamingInsert
import typr.dsl.DeleteBuilder
import typr.dsl.SelectBuilder
import typr.dsl.UpdateBuilder
import zio.ZIO
import zio.jdbc.SqlFragment.Segment
import zio.jdbc.SqlFragment.Setter
import zio.jdbc.UpdateResult
import zio.jdbc.ZConnection
import zio.stream.ZStream
import zio.jdbc.sqlInterpolator

class OnlyPkColumnsRepoImpl extends OnlyPkColumnsRepo {
  override def delete: DeleteBuilder[OnlyPkColumnsFields, OnlyPkColumnsRow] = DeleteBuilder.of(""""public"."only_pk_columns"""", OnlyPkColumnsFields.structure, OnlyPkColumnsRow.jdbcDecoder)

  override def deleteById(compositeId: OnlyPkColumnsId): ZIO[ZConnection, Throwable, Boolean] = sql"""delete from "public"."only_pk_columns" where "key_column_1" = ${Segment.paramSegment(compositeId.keyColumn1)(using Setter.stringSetter)} AND "key_column_2" = ${Segment.paramSegment(compositeId.keyColumn2)(using Setter.intSetter)}""".delete.map(_ > 0)

  override def deleteByIds(compositeIds: Array[OnlyPkColumnsId]): ZIO[ZConnection, Throwable, Long] = {
    val keyColumn1 = compositeIds.map(_.keyColumn1)
    val keyColumn2 = compositeIds.map(_.keyColumn2)
    sql"""delete
    from "public"."only_pk_columns"
    where ("key_column_1", "key_column_2")
    in (select unnest(${Segment.paramSegment(keyColumn1)(using adventureworks.StringArraySetter)}), unnest(${Segment.paramSegment(keyColumn2)(using adventureworks.IntArraySetter)}))
    """.delete
  }

  override def insert(unsaved: OnlyPkColumnsRow): ZIO[ZConnection, Throwable, OnlyPkColumnsRow] = {
    sql"""insert into "public"."only_pk_columns"("key_column_1", "key_column_2")
    values (${Segment.paramSegment(unsaved.keyColumn1)(using Setter.stringSetter)}, ${Segment.paramSegment(unsaved.keyColumn2)(using Setter.intSetter)}::int4)
    returning "key_column_1", "key_column_2"
    """.insertReturning(using OnlyPkColumnsRow.jdbcDecoder).map(_.updatedKeys.head)
  }

  override def insertStreaming(
    unsaved: ZStream[ZConnection, Throwable, OnlyPkColumnsRow],
    batchSize: Int = 10000
  ): ZIO[ZConnection, Throwable, Long] = streamingInsert(s"""COPY "public"."only_pk_columns"("key_column_1", "key_column_2") FROM STDIN""", batchSize, unsaved)(using OnlyPkColumnsRow.pgText)

  override def select: SelectBuilder[OnlyPkColumnsFields, OnlyPkColumnsRow] = SelectBuilder.of(""""public"."only_pk_columns"""", OnlyPkColumnsFields.structure, OnlyPkColumnsRow.jdbcDecoder)

  override def selectAll: ZStream[ZConnection, Throwable, OnlyPkColumnsRow] = sql"""select "key_column_1", "key_column_2" from "public"."only_pk_columns"""".query(using OnlyPkColumnsRow.jdbcDecoder).selectStream()

  override def selectById(compositeId: OnlyPkColumnsId): ZIO[ZConnection, Throwable, Option[OnlyPkColumnsRow]] = sql"""select "key_column_1", "key_column_2" from "public"."only_pk_columns" where "key_column_1" = ${Segment.paramSegment(compositeId.keyColumn1)(using Setter.stringSetter)} AND "key_column_2" = ${Segment.paramSegment(compositeId.keyColumn2)(using Setter.intSetter)}""".query(using OnlyPkColumnsRow.jdbcDecoder).selectOne

  override def selectByIds(compositeIds: Array[OnlyPkColumnsId]): ZStream[ZConnection, Throwable, OnlyPkColumnsRow] = {
    val keyColumn1 = compositeIds.map(_.keyColumn1)
    val keyColumn2 = compositeIds.map(_.keyColumn2)
    sql"""select "key_column_1", "key_column_2"
    from "public"."only_pk_columns"
    where ("key_column_1", "key_column_2")
    in (select unnest(${Segment.paramSegment(keyColumn1)(using adventureworks.StringArraySetter)}), unnest(${Segment.paramSegment(keyColumn2)(using adventureworks.IntArraySetter)}))
    """.query(using OnlyPkColumnsRow.jdbcDecoder).selectStream()
  }

  override def selectByIdsTracked(compositeIds: Array[OnlyPkColumnsId]): ZIO[ZConnection, Throwable, Map[OnlyPkColumnsId, OnlyPkColumnsRow]] = {
    selectByIds(compositeIds).runCollect.map { rows =>
      val byId = rows.view.map(x => (x.compositeId, x)).toMap
      compositeIds.view.flatMap(id => byId.get(id).map(x => (id, x))).toMap
    }
  }

  override def update: UpdateBuilder[OnlyPkColumnsFields, OnlyPkColumnsRow] = UpdateBuilder.of(""""public"."only_pk_columns"""", OnlyPkColumnsFields.structure, OnlyPkColumnsRow.jdbcDecoder)

  override def upsert(unsaved: OnlyPkColumnsRow): ZIO[ZConnection, Throwable, UpdateResult[OnlyPkColumnsRow]] = {
    sql"""insert into "public"."only_pk_columns"("key_column_1", "key_column_2")
    values (
      ${Segment.paramSegment(unsaved.keyColumn1)(using Setter.stringSetter)},
    ${Segment.paramSegment(unsaved.keyColumn2)(using Setter.intSetter)}::int4
    )
    on conflict ("key_column_1", "key_column_2")
    do update set "key_column_1" = EXCLUDED."key_column_1"
    returning "key_column_1", "key_column_2"""".insertReturning(using OnlyPkColumnsRow.jdbcDecoder)
  }

  /** NOTE: this functionality is not safe if you use auto-commit mode! it runs 3 SQL statements */
  override def upsertStreaming(
    unsaved: ZStream[ZConnection, Throwable, OnlyPkColumnsRow],
    batchSize: Int = 10000
  ): ZIO[ZConnection, Throwable, Long] = {
    val created = sql"""create temporary table only_pk_columns_TEMP (like "public"."only_pk_columns") on commit drop""".execute
    val copied = streamingInsert(s"""copy only_pk_columns_TEMP("key_column_1", "key_column_2") from stdin""", batchSize, unsaved)(using OnlyPkColumnsRow.pgText)
    val merged = sql"""insert into "public"."only_pk_columns"("key_column_1", "key_column_2")
    select * from only_pk_columns_TEMP
    on conflict ("key_column_1", "key_column_2")
    do nothing
    ;
    drop table only_pk_columns_TEMP;""".update
    created *> copied *> merged
  }
}