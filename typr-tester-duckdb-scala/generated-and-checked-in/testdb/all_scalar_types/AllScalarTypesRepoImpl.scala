/**
 * File has been automatically generated by `typo`.
 *
 * IF YOU CHANGE THIS FILE YOUR CHANGES WILL BE OVERWRITTEN.
 */
package testdb.all_scalar_types

import java.sql.Connection
import testdb.Mood
import typr.runtime.DuckDbTypes
import typr.scaladsl.DeleteBuilder
import typr.scaladsl.Dialect
import typr.scaladsl.DuckDbTypeOps
import typr.scaladsl.Fragment
import typr.scaladsl.ScalaDbTypes
import typr.scaladsl.SelectBuilder
import typr.scaladsl.UpdateBuilder
import typr.scaladsl.Fragment.sql

class AllScalarTypesRepoImpl extends AllScalarTypesRepo {
  override def delete: DeleteBuilder[AllScalarTypesFields, AllScalarTypesRow] = DeleteBuilder.of(""""all_scalar_types"""", AllScalarTypesFields.structure, Dialect.DUCKDB)

  override def deleteById(id: AllScalarTypesId)(using c: Connection): Boolean = sql"""delete from "all_scalar_types" where "id" = ${Fragment.encode(AllScalarTypesId.duckDbType, id)}""".update().runUnchecked(c) > 0

  override def deleteByIds(ids: Array[AllScalarTypesId])(using c: Connection): Int = {
    sql"""delete
    from "all_scalar_types"
    where "id" = ANY(${Fragment.encode(AllScalarTypesId.pgTypeArray, ids)})"""
      .update()
      .runUnchecked(c)
  }

  override def insert(unsaved: AllScalarTypesRow)(using c: Connection): AllScalarTypesRow = {
  sql"""insert into "all_scalar_types"("id", "col_tinyint", "col_smallint", "col_integer", "col_bigint", "col_hugeint", "col_utinyint", "col_usmallint", "col_uinteger", "col_ubigint", "col_float", "col_double", "col_decimal", "col_boolean", "col_varchar", "col_text", "col_blob", "col_date", "col_time", "col_timestamp", "col_timestamptz", "col_interval", "col_uuid", "col_json", "col_mood", "col_not_null")
    values (${Fragment.encode(AllScalarTypesId.duckDbType, unsaved.id)}, ${Fragment.encode(ScalaDbTypes.DuckDbTypes.tinyint.nullable, unsaved.colTinyint)}, ${Fragment.encode(ScalaDbTypes.DuckDbTypes.smallint.nullable, unsaved.colSmallint)}, ${Fragment.encode(ScalaDbTypes.DuckDbTypes.integer.nullable, unsaved.colInteger)}, ${Fragment.encode(ScalaDbTypes.DuckDbTypes.bigint.nullable, unsaved.colBigint)}, ${Fragment.encode(DuckDbTypes.hugeint.nullable, unsaved.colHugeint)}, ${Fragment.encode(ScalaDbTypes.DuckDbTypes.smallint.nullable, unsaved.colUtinyint)}, ${Fragment.encode(ScalaDbTypes.DuckDbTypes.integer.nullable, unsaved.colUsmallint)}, ${Fragment.encode(ScalaDbTypes.DuckDbTypes.bigint.nullable, unsaved.colUinteger)}, ${Fragment.encode(DuckDbTypes.ubigint.nullable, unsaved.colUbigint)}, ${Fragment.encode(ScalaDbTypes.DuckDbTypes.float_.nullable, unsaved.colFloat)}, ${Fragment.encode(ScalaDbTypes.DuckDbTypes.double_.nullable, unsaved.colDouble)}, ${Fragment.encode(ScalaDbTypes.DuckDbTypes.numeric.nullable, unsaved.colDecimal)}, ${Fragment.encode(ScalaDbTypes.DuckDbTypes.boolean_.nullable, unsaved.colBoolean)}, ${Fragment.encode(DuckDbTypes.varchar.nullable, unsaved.colVarchar)}, ${Fragment.encode(DuckDbTypes.varchar.nullable, unsaved.colText)}, ${Fragment.encode(DuckDbTypes.blob.nullable, unsaved.colBlob)}, ${Fragment.encode(DuckDbTypes.date.nullable, unsaved.colDate)}, ${Fragment.encode(DuckDbTypes.time.nullable, unsaved.colTime)}, ${Fragment.encode(DuckDbTypes.timestamp.nullable, unsaved.colTimestamp)}, ${Fragment.encode(DuckDbTypes.timestamptz.nullable, unsaved.colTimestamptz)}, ${Fragment.encode(DuckDbTypes.interval.nullable, unsaved.colInterval)}, ${Fragment.encode(DuckDbTypes.uuid.nullable, unsaved.colUuid)}, ${Fragment.encode(DuckDbTypes.json.nullable, unsaved.colJson)}, ${Fragment.encode(Mood.duckDbType.nullable, unsaved.colMood)}, ${Fragment.encode(DuckDbTypes.varchar, unsaved.colNotNull)})
    RETURNING "id", "col_tinyint", "col_smallint", "col_integer", "col_bigint", "col_hugeint", "col_utinyint", "col_usmallint", "col_uinteger", "col_ubigint", "col_float", "col_double", "col_decimal", "col_boolean", "col_varchar", "col_text", "col_blob", "col_date", "col_time", "col_timestamp", "col_timestamptz", "col_interval", "col_uuid", "col_json", "col_mood", "col_not_null"
    """
    .updateReturning(AllScalarTypesRow.`_rowParser`.exactlyOne()).runUnchecked(c)
  }

  override def select: SelectBuilder[AllScalarTypesFields, AllScalarTypesRow] = SelectBuilder.of(""""all_scalar_types"""", AllScalarTypesFields.structure, AllScalarTypesRow.`_rowParser`, Dialect.DUCKDB)

  override def selectAll(using c: Connection): List[AllScalarTypesRow] = {
    sql"""select "id", "col_tinyint", "col_smallint", "col_integer", "col_bigint", "col_hugeint", "col_utinyint", "col_usmallint", "col_uinteger", "col_ubigint", "col_float", "col_double", "col_decimal", "col_boolean", "col_varchar", "col_text", "col_blob", "col_date", "col_time", "col_timestamp", "col_timestamptz", "col_interval", "col_uuid", "col_json", "col_mood", "col_not_null"
    from "all_scalar_types"
    """.query(AllScalarTypesRow.`_rowParser`.all()).runUnchecked(c)
  }

  override def selectById(id: AllScalarTypesId)(using c: Connection): Option[AllScalarTypesRow] = {
    sql"""select "id", "col_tinyint", "col_smallint", "col_integer", "col_bigint", "col_hugeint", "col_utinyint", "col_usmallint", "col_uinteger", "col_ubigint", "col_float", "col_double", "col_decimal", "col_boolean", "col_varchar", "col_text", "col_blob", "col_date", "col_time", "col_timestamp", "col_timestamptz", "col_interval", "col_uuid", "col_json", "col_mood", "col_not_null"
    from "all_scalar_types"
    where "id" = ${Fragment.encode(AllScalarTypesId.duckDbType, id)}""".query(AllScalarTypesRow.`_rowParser`.first()).runUnchecked(c)
  }

  override def selectByIds(ids: Array[AllScalarTypesId])(using c: Connection): List[AllScalarTypesRow] = {
    sql"""select "id", "col_tinyint", "col_smallint", "col_integer", "col_bigint", "col_hugeint", "col_utinyint", "col_usmallint", "col_uinteger", "col_ubigint", "col_float", "col_double", "col_decimal", "col_boolean", "col_varchar", "col_text", "col_blob", "col_date", "col_time", "col_timestamp", "col_timestamptz", "col_interval", "col_uuid", "col_json", "col_mood", "col_not_null"
    from "all_scalar_types"
    where "id" = ANY(${Fragment.encode(AllScalarTypesId.pgTypeArray, ids)})""".query(AllScalarTypesRow.`_rowParser`.all()).runUnchecked(c)
  }

  override def selectByIdsTracked(ids: Array[AllScalarTypesId])(using c: Connection): Map[AllScalarTypesId, AllScalarTypesRow] = {
    val ret: scala.collection.mutable.Map[AllScalarTypesId, AllScalarTypesRow] = scala.collection.mutable.Map.empty[AllScalarTypesId, AllScalarTypesRow]
    selectByIds(ids)(using c).foreach(row => ret.put(row.id, row): @scala.annotation.nowarn)
    return ret.toMap
  }

  override def update: UpdateBuilder[AllScalarTypesFields, AllScalarTypesRow] = UpdateBuilder.of(""""all_scalar_types"""", AllScalarTypesFields.structure, AllScalarTypesRow.`_rowParser`, Dialect.DUCKDB)

  override def update(row: AllScalarTypesRow)(using c: Connection): Boolean = {
    val id: AllScalarTypesId = row.id
    return sql"""update "all_scalar_types"
    set "col_tinyint" = ${Fragment.encode(ScalaDbTypes.DuckDbTypes.tinyint.nullable, row.colTinyint)},
    "col_smallint" = ${Fragment.encode(ScalaDbTypes.DuckDbTypes.smallint.nullable, row.colSmallint)},
    "col_integer" = ${Fragment.encode(ScalaDbTypes.DuckDbTypes.integer.nullable, row.colInteger)},
    "col_bigint" = ${Fragment.encode(ScalaDbTypes.DuckDbTypes.bigint.nullable, row.colBigint)},
    "col_hugeint" = ${Fragment.encode(DuckDbTypes.hugeint.nullable, row.colHugeint)},
    "col_utinyint" = ${Fragment.encode(ScalaDbTypes.DuckDbTypes.smallint.nullable, row.colUtinyint)},
    "col_usmallint" = ${Fragment.encode(ScalaDbTypes.DuckDbTypes.integer.nullable, row.colUsmallint)},
    "col_uinteger" = ${Fragment.encode(ScalaDbTypes.DuckDbTypes.bigint.nullable, row.colUinteger)},
    "col_ubigint" = ${Fragment.encode(DuckDbTypes.ubigint.nullable, row.colUbigint)},
    "col_float" = ${Fragment.encode(ScalaDbTypes.DuckDbTypes.float_.nullable, row.colFloat)},
    "col_double" = ${Fragment.encode(ScalaDbTypes.DuckDbTypes.double_.nullable, row.colDouble)},
    "col_decimal" = ${Fragment.encode(ScalaDbTypes.DuckDbTypes.numeric.nullable, row.colDecimal)},
    "col_boolean" = ${Fragment.encode(ScalaDbTypes.DuckDbTypes.boolean_.nullable, row.colBoolean)},
    "col_varchar" = ${Fragment.encode(DuckDbTypes.varchar.nullable, row.colVarchar)},
    "col_text" = ${Fragment.encode(DuckDbTypes.varchar.nullable, row.colText)},
    "col_blob" = ${Fragment.encode(DuckDbTypes.blob.nullable, row.colBlob)},
    "col_date" = ${Fragment.encode(DuckDbTypes.date.nullable, row.colDate)},
    "col_time" = ${Fragment.encode(DuckDbTypes.time.nullable, row.colTime)},
    "col_timestamp" = ${Fragment.encode(DuckDbTypes.timestamp.nullable, row.colTimestamp)},
    "col_timestamptz" = ${Fragment.encode(DuckDbTypes.timestamptz.nullable, row.colTimestamptz)},
    "col_interval" = ${Fragment.encode(DuckDbTypes.interval.nullable, row.colInterval)},
    "col_uuid" = ${Fragment.encode(DuckDbTypes.uuid.nullable, row.colUuid)},
    "col_json" = ${Fragment.encode(DuckDbTypes.json.nullable, row.colJson)},
    "col_mood" = ${Fragment.encode(Mood.duckDbType.nullable, row.colMood)},
    "col_not_null" = ${Fragment.encode(DuckDbTypes.varchar, row.colNotNull)}
    where "id" = ${Fragment.encode(AllScalarTypesId.duckDbType, id)}""".update().runUnchecked(c) > 0
  }

  override def upsert(unsaved: AllScalarTypesRow)(using c: Connection): AllScalarTypesRow = {
  sql"""INSERT INTO "all_scalar_types"("id", "col_tinyint", "col_smallint", "col_integer", "col_bigint", "col_hugeint", "col_utinyint", "col_usmallint", "col_uinteger", "col_ubigint", "col_float", "col_double", "col_decimal", "col_boolean", "col_varchar", "col_text", "col_blob", "col_date", "col_time", "col_timestamp", "col_timestamptz", "col_interval", "col_uuid", "col_json", "col_mood", "col_not_null")
    VALUES (${Fragment.encode(AllScalarTypesId.duckDbType, unsaved.id)}, ${Fragment.encode(ScalaDbTypes.DuckDbTypes.tinyint.nullable, unsaved.colTinyint)}, ${Fragment.encode(ScalaDbTypes.DuckDbTypes.smallint.nullable, unsaved.colSmallint)}, ${Fragment.encode(ScalaDbTypes.DuckDbTypes.integer.nullable, unsaved.colInteger)}, ${Fragment.encode(ScalaDbTypes.DuckDbTypes.bigint.nullable, unsaved.colBigint)}, ${Fragment.encode(DuckDbTypes.hugeint.nullable, unsaved.colHugeint)}, ${Fragment.encode(ScalaDbTypes.DuckDbTypes.smallint.nullable, unsaved.colUtinyint)}, ${Fragment.encode(ScalaDbTypes.DuckDbTypes.integer.nullable, unsaved.colUsmallint)}, ${Fragment.encode(ScalaDbTypes.DuckDbTypes.bigint.nullable, unsaved.colUinteger)}, ${Fragment.encode(DuckDbTypes.ubigint.nullable, unsaved.colUbigint)}, ${Fragment.encode(ScalaDbTypes.DuckDbTypes.float_.nullable, unsaved.colFloat)}, ${Fragment.encode(ScalaDbTypes.DuckDbTypes.double_.nullable, unsaved.colDouble)}, ${Fragment.encode(ScalaDbTypes.DuckDbTypes.numeric.nullable, unsaved.colDecimal)}, ${Fragment.encode(ScalaDbTypes.DuckDbTypes.boolean_.nullable, unsaved.colBoolean)}, ${Fragment.encode(DuckDbTypes.varchar.nullable, unsaved.colVarchar)}, ${Fragment.encode(DuckDbTypes.varchar.nullable, unsaved.colText)}, ${Fragment.encode(DuckDbTypes.blob.nullable, unsaved.colBlob)}, ${Fragment.encode(DuckDbTypes.date.nullable, unsaved.colDate)}, ${Fragment.encode(DuckDbTypes.time.nullable, unsaved.colTime)}, ${Fragment.encode(DuckDbTypes.timestamp.nullable, unsaved.colTimestamp)}, ${Fragment.encode(DuckDbTypes.timestamptz.nullable, unsaved.colTimestamptz)}, ${Fragment.encode(DuckDbTypes.interval.nullable, unsaved.colInterval)}, ${Fragment.encode(DuckDbTypes.uuid.nullable, unsaved.colUuid)}, ${Fragment.encode(DuckDbTypes.json.nullable, unsaved.colJson)}, ${Fragment.encode(Mood.duckDbType.nullable, unsaved.colMood)}, ${Fragment.encode(DuckDbTypes.varchar, unsaved.colNotNull)})
    ON CONFLICT ("id")
    DO UPDATE SET
      "col_tinyint" = EXCLUDED."col_tinyint",
    "col_smallint" = EXCLUDED."col_smallint",
    "col_integer" = EXCLUDED."col_integer",
    "col_bigint" = EXCLUDED."col_bigint",
    "col_hugeint" = EXCLUDED."col_hugeint",
    "col_utinyint" = EXCLUDED."col_utinyint",
    "col_usmallint" = EXCLUDED."col_usmallint",
    "col_uinteger" = EXCLUDED."col_uinteger",
    "col_ubigint" = EXCLUDED."col_ubigint",
    "col_float" = EXCLUDED."col_float",
    "col_double" = EXCLUDED."col_double",
    "col_decimal" = EXCLUDED."col_decimal",
    "col_boolean" = EXCLUDED."col_boolean",
    "col_varchar" = EXCLUDED."col_varchar",
    "col_text" = EXCLUDED."col_text",
    "col_blob" = EXCLUDED."col_blob",
    "col_date" = EXCLUDED."col_date",
    "col_time" = EXCLUDED."col_time",
    "col_timestamp" = EXCLUDED."col_timestamp",
    "col_timestamptz" = EXCLUDED."col_timestamptz",
    "col_interval" = EXCLUDED."col_interval",
    "col_uuid" = EXCLUDED."col_uuid",
    "col_json" = EXCLUDED."col_json",
    "col_mood" = EXCLUDED."col_mood",
    "col_not_null" = EXCLUDED."col_not_null"
    RETURNING "id", "col_tinyint", "col_smallint", "col_integer", "col_bigint", "col_hugeint", "col_utinyint", "col_usmallint", "col_uinteger", "col_ubigint", "col_float", "col_double", "col_decimal", "col_boolean", "col_varchar", "col_text", "col_blob", "col_date", "col_time", "col_timestamp", "col_timestamptz", "col_interval", "col_uuid", "col_json", "col_mood", "col_not_null""""
    .updateReturning(AllScalarTypesRow.`_rowParser`.exactlyOne())
    .runUnchecked(c)
  }

  override def upsertBatch(unsaved: Iterator[AllScalarTypesRow])(using c: Connection): List[AllScalarTypesRow] = {
    sql"""INSERT INTO "all_scalar_types"("id", "col_tinyint", "col_smallint", "col_integer", "col_bigint", "col_hugeint", "col_utinyint", "col_usmallint", "col_uinteger", "col_ubigint", "col_float", "col_double", "col_decimal", "col_boolean", "col_varchar", "col_text", "col_blob", "col_date", "col_time", "col_timestamp", "col_timestamptz", "col_interval", "col_uuid", "col_json", "col_mood", "col_not_null")
    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
    ON CONFLICT ("id")
    DO UPDATE SET
      "col_tinyint" = EXCLUDED."col_tinyint",
    "col_smallint" = EXCLUDED."col_smallint",
    "col_integer" = EXCLUDED."col_integer",
    "col_bigint" = EXCLUDED."col_bigint",
    "col_hugeint" = EXCLUDED."col_hugeint",
    "col_utinyint" = EXCLUDED."col_utinyint",
    "col_usmallint" = EXCLUDED."col_usmallint",
    "col_uinteger" = EXCLUDED."col_uinteger",
    "col_ubigint" = EXCLUDED."col_ubigint",
    "col_float" = EXCLUDED."col_float",
    "col_double" = EXCLUDED."col_double",
    "col_decimal" = EXCLUDED."col_decimal",
    "col_boolean" = EXCLUDED."col_boolean",
    "col_varchar" = EXCLUDED."col_varchar",
    "col_text" = EXCLUDED."col_text",
    "col_blob" = EXCLUDED."col_blob",
    "col_date" = EXCLUDED."col_date",
    "col_time" = EXCLUDED."col_time",
    "col_timestamp" = EXCLUDED."col_timestamp",
    "col_timestamptz" = EXCLUDED."col_timestamptz",
    "col_interval" = EXCLUDED."col_interval",
    "col_uuid" = EXCLUDED."col_uuid",
    "col_json" = EXCLUDED."col_json",
    "col_mood" = EXCLUDED."col_mood",
    "col_not_null" = EXCLUDED."col_not_null"
    RETURNING "id", "col_tinyint", "col_smallint", "col_integer", "col_bigint", "col_hugeint", "col_utinyint", "col_usmallint", "col_uinteger", "col_ubigint", "col_float", "col_double", "col_decimal", "col_boolean", "col_varchar", "col_text", "col_blob", "col_date", "col_time", "col_timestamp", "col_timestamptz", "col_interval", "col_uuid", "col_json", "col_mood", "col_not_null""""
      .updateReturningEach(AllScalarTypesRow.`_rowParser`, unsaved)
    .runUnchecked(c)
  }
}