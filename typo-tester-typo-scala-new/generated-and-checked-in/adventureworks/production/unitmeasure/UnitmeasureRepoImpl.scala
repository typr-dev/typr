/**
 * File has been automatically generated by `typo`.
 *
 * IF YOU CHANGE THIS FILE YOUR CHANGES WILL BE OVERWRITTEN.
 */
package adventureworks.production.unitmeasure

import adventureworks.public.Name
import java.sql.Connection
import scala.collection.mutable.ListBuffer
import typo.runtime.PgTypes
import typo.runtime.streamingInsert
import typo.scaladsl.DeleteBuilder
import typo.scaladsl.Dialect
import typo.scaladsl.Fragment
import typo.scaladsl.ScalaIteratorOps
import typo.scaladsl.SelectBuilder
import typo.scaladsl.UpdateBuilder
import typo.scaladsl.Fragment.sql

class UnitmeasureRepoImpl extends UnitmeasureRepo {
  override def delete: DeleteBuilder[UnitmeasureFields, UnitmeasureRow] = DeleteBuilder.of(""""production"."unitmeasure"""", UnitmeasureFields.structure, Dialect.POSTGRESQL)

  override def deleteById(unitmeasurecode: UnitmeasureId)(using c: Connection): Boolean = sql"""delete from "production"."unitmeasure" where "unitmeasurecode" = ${Fragment.encode(UnitmeasureId.pgType, unitmeasurecode)}""".update().runUnchecked(c) > 0

  override def deleteByIds(unitmeasurecodes: Array[UnitmeasureId])(using c: Connection): Int = {
    sql"""delete
    from "production"."unitmeasure"
    where "unitmeasurecode" = ANY(${Fragment.encode(UnitmeasureId.pgTypeArray, unitmeasurecodes)})"""
      .update()
      .runUnchecked(c)
  }

  override def insert(unsaved: UnitmeasureRow)(using c: Connection): UnitmeasureRow = {
  sql"""insert into "production"."unitmeasure"("unitmeasurecode", "name", "modifieddate")
    values (${Fragment.encode(UnitmeasureId.pgType, unsaved.unitmeasurecode)}::bpchar, ${Fragment.encode(Name.pgType, unsaved.name)}::varchar, ${Fragment.encode(PgTypes.timestamp, unsaved.modifieddate)}::timestamp)
    RETURNING "unitmeasurecode", "name", "modifieddate"
    """
    .updateReturning(UnitmeasureRow.`_rowParser`.exactlyOne()).runUnchecked(c)
  }

  override def insert(unsaved: UnitmeasureRowUnsaved)(using c: Connection): UnitmeasureRow = {
    val columns: ListBuffer[Fragment] = ListBuffer()
    val values: ListBuffer[Fragment] = ListBuffer()
    columns.addOne(Fragment.lit(""""unitmeasurecode"""")): @scala.annotation.nowarn
    values.addOne(sql"${Fragment.encode(UnitmeasureId.pgType, unsaved.unitmeasurecode)}::bpchar"): @scala.annotation.nowarn
    columns.addOne(Fragment.lit(""""name"""")): @scala.annotation.nowarn
    values.addOne(sql"${Fragment.encode(Name.pgType, unsaved.name)}::varchar"): @scala.annotation.nowarn
    unsaved.modifieddate.visit(
      {  },
      value => { columns.addOne(Fragment.lit(""""modifieddate"""")): @scala.annotation.nowarn; values.addOne(sql"${Fragment.encode(PgTypes.timestamp, value)}::timestamp"): @scala.annotation.nowarn }
    );
    val q: Fragment = {
      sql"""insert into "production"."unitmeasure"(${Fragment.comma(columns)})
      values (${Fragment.comma(values)})
      RETURNING "unitmeasurecode", "name", "modifieddate"
      """
    }
    return q.updateReturning(UnitmeasureRow.`_rowParser`.exactlyOne()).runUnchecked(c)
  }

  override def insertStreaming(
    unsaved: Iterator[UnitmeasureRow],
    batchSize: Int = 10000
  )(using c: Connection): Long = streamingInsert.insertUnchecked(s"""COPY "production"."unitmeasure"("unitmeasurecode", "name", "modifieddate") FROM STDIN""", batchSize, unsaved.toJavaIterator, c, UnitmeasureRow.pgText)

  /** NOTE: this functionality requires PostgreSQL 16 or later! */
  override def insertUnsavedStreaming(
    unsaved: Iterator[UnitmeasureRowUnsaved],
    batchSize: Int = 10000
  )(using c: Connection): Long = streamingInsert.insertUnchecked(s"""COPY "production"."unitmeasure"("unitmeasurecode", "name", "modifieddate") FROM STDIN (DEFAULT '__DEFAULT_VALUE__')""", batchSize, unsaved.toJavaIterator, c, UnitmeasureRowUnsaved.pgText)

  override def select: SelectBuilder[UnitmeasureFields, UnitmeasureRow] = SelectBuilder.of(""""production"."unitmeasure"""", UnitmeasureFields.structure, UnitmeasureRow.`_rowParser`, Dialect.POSTGRESQL)

  override def selectAll(using c: Connection): List[UnitmeasureRow] = {
    sql"""select "unitmeasurecode", "name", "modifieddate"
    from "production"."unitmeasure"
    """.query(UnitmeasureRow.`_rowParser`.all()).runUnchecked(c)
  }

  override def selectById(unitmeasurecode: UnitmeasureId)(using c: Connection): Option[UnitmeasureRow] = {
    sql"""select "unitmeasurecode", "name", "modifieddate"
    from "production"."unitmeasure"
    where "unitmeasurecode" = ${Fragment.encode(UnitmeasureId.pgType, unitmeasurecode)}""".query(UnitmeasureRow.`_rowParser`.first()).runUnchecked(c)
  }

  override def selectByIds(unitmeasurecodes: Array[UnitmeasureId])(using c: Connection): List[UnitmeasureRow] = {
    sql"""select "unitmeasurecode", "name", "modifieddate"
    from "production"."unitmeasure"
    where "unitmeasurecode" = ANY(${Fragment.encode(UnitmeasureId.pgTypeArray, unitmeasurecodes)})""".query(UnitmeasureRow.`_rowParser`.all()).runUnchecked(c)
  }

  override def selectByIdsTracked(unitmeasurecodes: Array[UnitmeasureId])(using c: Connection): Map[UnitmeasureId, UnitmeasureRow] = {
    val ret: scala.collection.mutable.Map[UnitmeasureId, UnitmeasureRow] = scala.collection.mutable.Map.empty[UnitmeasureId, UnitmeasureRow]
    selectByIds(unitmeasurecodes)(using c).foreach(row => ret.put(row.unitmeasurecode, row): @scala.annotation.nowarn)
    return ret.toMap
  }

  override def update: UpdateBuilder[UnitmeasureFields, UnitmeasureRow] = UpdateBuilder.of(""""production"."unitmeasure"""", UnitmeasureFields.structure, UnitmeasureRow.`_rowParser`, Dialect.POSTGRESQL)

  override def update(row: UnitmeasureRow)(using c: Connection): Boolean = {
    val unitmeasurecode: UnitmeasureId = row.unitmeasurecode
    return sql"""update "production"."unitmeasure"
    set "name" = ${Fragment.encode(Name.pgType, row.name)}::varchar,
    "modifieddate" = ${Fragment.encode(PgTypes.timestamp, row.modifieddate)}::timestamp
    where "unitmeasurecode" = ${Fragment.encode(UnitmeasureId.pgType, unitmeasurecode)}""".update().runUnchecked(c) > 0
  }

  override def upsert(unsaved: UnitmeasureRow)(using c: Connection): UnitmeasureRow = {
  sql"""insert into "production"."unitmeasure"("unitmeasurecode", "name", "modifieddate")
    values (${Fragment.encode(UnitmeasureId.pgType, unsaved.unitmeasurecode)}::bpchar, ${Fragment.encode(Name.pgType, unsaved.name)}::varchar, ${Fragment.encode(PgTypes.timestamp, unsaved.modifieddate)}::timestamp)
    on conflict ("unitmeasurecode")
    do update set
      "name" = EXCLUDED."name",
    "modifieddate" = EXCLUDED."modifieddate"
    returning "unitmeasurecode", "name", "modifieddate""""
    .updateReturning(UnitmeasureRow.`_rowParser`.exactlyOne())
    .runUnchecked(c)
  }

  override def upsertBatch(unsaved: Iterator[UnitmeasureRow])(using c: Connection): List[UnitmeasureRow] = {
    sql"""insert into "production"."unitmeasure"("unitmeasurecode", "name", "modifieddate")
    values (?::bpchar, ?::varchar, ?::timestamp)
    on conflict ("unitmeasurecode")
    do update set
      "name" = EXCLUDED."name",
    "modifieddate" = EXCLUDED."modifieddate"
    returning "unitmeasurecode", "name", "modifieddate""""
      .updateManyReturning(UnitmeasureRow.`_rowParser`, unsaved)
    .runUnchecked(c)
  }

  /** NOTE: this functionality is not safe if you use auto-commit mode! it runs 3 SQL statements */
  override def upsertStreaming(
    unsaved: Iterator[UnitmeasureRow],
    batchSize: Int = 10000
  )(using c: Connection): Int = {
    sql"""create temporary table unitmeasure_TEMP (like "production"."unitmeasure") on commit drop""".update().runUnchecked(c): @scala.annotation.nowarn
    streamingInsert.insertUnchecked(s"""copy unitmeasure_TEMP("unitmeasurecode", "name", "modifieddate") from stdin""", batchSize, unsaved.toJavaIterator, c, UnitmeasureRow.pgText): @scala.annotation.nowarn
    return sql"""insert into "production"."unitmeasure"("unitmeasurecode", "name", "modifieddate")
    select * from unitmeasure_TEMP
    on conflict ("unitmeasurecode")
    do update set
      "name" = EXCLUDED."name",
    "modifieddate" = EXCLUDED."modifieddate"
    ;
    drop table unitmeasure_TEMP;""".update().runUnchecked(c)
  }
}