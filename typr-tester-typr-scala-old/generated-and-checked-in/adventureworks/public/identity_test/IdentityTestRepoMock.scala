/**
 * File has been automatically generated by `typo`.
 *
 * IF YOU CHANGE THIS FILE YOUR CHANGES WILL BE OVERWRITTEN.
 */
package adventureworks.public.identity_test

import java.lang.RuntimeException
import java.sql.Connection
import java.util.ArrayList
import java.util.HashMap
import java.util.Optional
import java.util.function.Function
import java.util.stream.Collectors
import typr.dsl.DeleteBuilder
import typr.dsl.DeleteBuilderMock
import typr.dsl.DeleteParams
import typr.dsl.SelectBuilder
import typr.dsl.SelectBuilderMock
import typr.dsl.SelectParams
import typr.dsl.UpdateBuilder
import typr.dsl.UpdateBuilderMock
import typr.dsl.UpdateParams

case class IdentityTestRepoMock(
  toRow: IdentityTestRowUnsaved => IdentityTestRow,
  map: HashMap[IdentityTestId, IdentityTestRow] = new HashMap[IdentityTestId, IdentityTestRow]()
) extends IdentityTestRepo {
  override def delete: DeleteBuilder[IdentityTestFields, IdentityTestRow] = DeleteBuilderMock(IdentityTestFields.structure, () => new ArrayList(map.values()), DeleteParams.empty(), row => row.name, id => map.remove(id): @scala.annotation.nowarn)

  override def deleteById(name: IdentityTestId)(using c: Connection): java.lang.Boolean = Optional.ofNullable(map.remove(name)).isPresent()

  override def deleteByIds(names: Array[IdentityTestId])(using c: Connection): Integer = {
    var count = 0
    names.foreach { id => if (Optional.ofNullable(map.remove(id)).isPresent()) {
      count = count + 1
    } }
    return count
  }

  override def insert(unsaved: IdentityTestRow)(using c: Connection): IdentityTestRow = {
    if (map.containsKey(unsaved.name)) {
      throw new RuntimeException(s"id ${unsaved.name} already exists")
    }
    map.put(unsaved.name, unsaved): @scala.annotation.nowarn
    return unsaved
  }

  override def insert(unsaved: IdentityTestRowUnsaved)(using c: Connection): IdentityTestRow = insert(toRow(unsaved))(using c)

  override def insertStreaming(
    unsaved: java.util.Iterator[IdentityTestRow],
    batchSize: Integer = 10000
  )(using c: Connection): java.lang.Long = {
    var count = 0L
    while (unsaved.hasNext()) {
      val row = unsaved.next()
      map.put(row.name, row): @scala.annotation.nowarn
      count = count + 1L
    }
    return count
  }

  /** NOTE: this functionality requires PostgreSQL 16 or later! */
  override def insertUnsavedStreaming(
    unsaved: java.util.Iterator[IdentityTestRowUnsaved],
    batchSize: Integer = 10000
  )(using c: Connection): java.lang.Long = {
    var count = 0L
    while (unsaved.hasNext()) {
      val unsavedRow = unsaved.next()
      val row = toRow(unsavedRow)
      map.put(row.name, row): @scala.annotation.nowarn
      count = count + 1L
    }
    return count
  }

  override def select: SelectBuilder[IdentityTestFields, IdentityTestRow] = SelectBuilderMock(IdentityTestFields.structure, () => new ArrayList(map.values()), SelectParams.empty())

  override def selectAll(using c: Connection): java.util.List[IdentityTestRow] = new ArrayList(map.values())

  override def selectById(name: IdentityTestId)(using c: Connection): Optional[IdentityTestRow] = Optional.ofNullable(map.get(name))

  override def selectByIds(names: Array[IdentityTestId])(using c: Connection): java.util.List[IdentityTestRow] = {
    val result = new ArrayList[IdentityTestRow]()
    names.foreach { id => val opt = Optional.ofNullable(map.get(id)); if (opt.isPresent()) {
      result.add(opt.get()): @scala.annotation.nowarn
    } }
    return result
  }

  override def selectByIdsTracked(names: Array[IdentityTestId])(using c: Connection): java.util.Map[IdentityTestId, IdentityTestRow] = selectByIds(names)(using c).stream().collect(Collectors.toMap((row: IdentityTestRow) => row.name, Function.identity()))

  override def update: UpdateBuilder[IdentityTestFields, IdentityTestRow] = UpdateBuilderMock(IdentityTestFields.structure, () => new ArrayList(map.values()), UpdateParams.empty(), row => row)

  override def update(row: IdentityTestRow)(using c: Connection): java.lang.Boolean = {
    val shouldUpdate = Optional.ofNullable(map.get(row.name)).filter(oldRow => (oldRow != row)).isPresent()
    if (shouldUpdate) {
      map.put(row.name, row): @scala.annotation.nowarn
    }
    return shouldUpdate
  }

  override def upsert(unsaved: IdentityTestRow)(using c: Connection): IdentityTestRow = {
    map.put(unsaved.name, unsaved): @scala.annotation.nowarn
    return unsaved
  }

  override def upsertBatch(unsaved: java.util.Iterator[IdentityTestRow])(using c: Connection): java.util.List[IdentityTestRow] = {
    val result = new ArrayList[IdentityTestRow]()
    while (unsaved.hasNext()) {
      val row = unsaved.next()
      map.put(row.name, row): @scala.annotation.nowarn
      result.add(row): @scala.annotation.nowarn
    }
    return result
  }

  /** NOTE: this functionality is not safe if you use auto-commit mode! it runs 3 SQL statements */
  override def upsertStreaming(
    unsaved: java.util.Iterator[IdentityTestRow],
    batchSize: Integer = 10000
  )(using c: Connection): Integer = {
    var count = 0
    while (unsaved.hasNext()) {
      val row = unsaved.next()
      map.put(row.name, row): @scala.annotation.nowarn
      count = count + 1
    }
    return count
  }
}