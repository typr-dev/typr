/**
 * File has been automatically generated by `typo`.
 *
 * IF YOU CHANGE THIS FILE YOUR CHANGES WILL BE OVERWRITTEN.
 */
package adventureworks.public.only_pk_columns

import java.lang.RuntimeException
import java.sql.Connection
import java.util.ArrayList
import java.util.HashMap
import java.util.Optional
import java.util.function.Function
import java.util.stream.Collectors
import typo.dsl.DeleteBuilder
import typo.dsl.DeleteBuilder.DeleteBuilderMock
import typo.dsl.DeleteParams
import typo.dsl.SelectBuilder
import typo.dsl.SelectBuilderMock
import typo.dsl.SelectParams
import typo.dsl.UpdateBuilder
import typo.dsl.UpdateBuilder.UpdateBuilderMock
import typo.dsl.UpdateParams

case class OnlyPkColumnsRepoMock(map: HashMap[OnlyPkColumnsId, OnlyPkColumnsRow] = new HashMap[OnlyPkColumnsId, OnlyPkColumnsRow]()) extends OnlyPkColumnsRepo {
  override def delete: DeleteBuilder[OnlyPkColumnsFields, OnlyPkColumnsRow] = {
    new DeleteBuilderMock(
      OnlyPkColumnsFields.structure,
      () => new ArrayList(map.values()),
      DeleteParams.empty(),
      row => row.compositeId,
      id => map.remove(id): @scala.annotation.nowarn
    )
  }

  override def deleteById(compositeId: OnlyPkColumnsId)(using c: Connection): java.lang.Boolean = Optional.ofNullable(map.remove(compositeId)).isPresent()

  override def deleteByIds(compositeIds: Array[OnlyPkColumnsId])(using c: Connection): Integer = {
    var count = 0
    compositeIds.foreach { id => if (Optional.ofNullable(map.remove(id)).isPresent()) {
      count = count + 1
    } }
    return count
  }

  override def insert(unsaved: OnlyPkColumnsRow)(using c: Connection): OnlyPkColumnsRow = {
    if (map.containsKey(unsaved.compositeId)) {
      throw new RuntimeException(s"id $unsaved.compositeId already exists")
    }
    map.put(unsaved.compositeId, unsaved): @scala.annotation.nowarn
    return unsaved
  }

  override def insertStreaming(
    unsaved: java.util.Iterator[OnlyPkColumnsRow],
    batchSize: Integer = 10000
  )(using c: Connection): java.lang.Long = {
    var count = 0L
    while (unsaved.hasNext()) {
      val row = unsaved.next()
      map.put(row.compositeId, row): @scala.annotation.nowarn
      count = count + 1L
    }
    return count
  }

  override def select: SelectBuilder[OnlyPkColumnsFields, OnlyPkColumnsRow] = new SelectBuilderMock(OnlyPkColumnsFields.structure, () => new ArrayList(map.values()), SelectParams.empty())

  override def selectAll(using c: Connection): java.util.List[OnlyPkColumnsRow] = new ArrayList(map.values())

  override def selectById(compositeId: OnlyPkColumnsId)(using c: Connection): Optional[OnlyPkColumnsRow] = Optional.ofNullable(map.get(compositeId))

  override def selectByIds(compositeIds: Array[OnlyPkColumnsId])(using c: Connection): java.util.List[OnlyPkColumnsRow] = {
    val result = new ArrayList[OnlyPkColumnsRow]()
    compositeIds.foreach { id => val opt = Optional.ofNullable(map.get(id)); if (opt.isPresent()) {
      result.add(opt.get()): @scala.annotation.nowarn
    } }
    return result
  }

  override def selectByIdsTracked(compositeIds: Array[OnlyPkColumnsId])(using c: Connection): java.util.Map[OnlyPkColumnsId, OnlyPkColumnsRow] = selectByIds(compositeIds)(using c).stream().collect(Collectors.toMap((row: OnlyPkColumnsRow) => row.compositeId, Function.identity()))

  override def update: UpdateBuilder[OnlyPkColumnsFields, OnlyPkColumnsRow] = {
    new UpdateBuilderMock(
      OnlyPkColumnsFields.structure,
      () => new ArrayList(map.values()),
      UpdateParams.empty(),
      row => row
    )
  }

  override def upsert(unsaved: OnlyPkColumnsRow)(using c: Connection): OnlyPkColumnsRow = {
    map.put(unsaved.compositeId, unsaved): @scala.annotation.nowarn
    return unsaved
  }

  override def upsertBatch(unsaved: java.util.Iterator[OnlyPkColumnsRow])(using c: Connection): java.util.List[OnlyPkColumnsRow] = {
    val result = new ArrayList[OnlyPkColumnsRow]()
    while (unsaved.hasNext()) {
      val row = unsaved.next()
      map.put(row.compositeId, row): @scala.annotation.nowarn
      result.add(row): @scala.annotation.nowarn
    }
    return result
  }

  /** NOTE: this functionality is not safe if you use auto-commit mode! it runs 3 SQL statements */
  override def upsertStreaming(
    unsaved: java.util.Iterator[OnlyPkColumnsRow],
    batchSize: Integer = 10000
  )(using c: Connection): Integer = {
    var count = 0
    while (unsaved.hasNext()) {
      val row = unsaved.next()
      map.put(row.compositeId, row): @scala.annotation.nowarn
      count = count + 1
    }
    return count
  }
}